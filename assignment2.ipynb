{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Loan Amount</th>\n",
       "      <th>Loan Purpose</th>\n",
       "      <th>Employment Status</th>\n",
       "      <th>Years at Current Job</th>\n",
       "      <th>Payment History</th>\n",
       "      <th>Debt-to-Income Ratio</th>\n",
       "      <th>Assets Value</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Previous Defaults</th>\n",
       "      <th>Marital Status Change</th>\n",
       "      <th>Risk Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>72799.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>45713.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>19</td>\n",
       "      <td>Poor</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>120228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Port Elizabeth</td>\n",
       "      <td>AS</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.0</td>\n",
       "      <td>33835.0</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Employed</td>\n",
       "      <td>6</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.148920</td>\n",
       "      <td>55849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North Catherine</td>\n",
       "      <td>OH</td>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Single</td>\n",
       "      <td>55687.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>36623.0</td>\n",
       "      <td>Home</td>\n",
       "      <td>Employed</td>\n",
       "      <td>8</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.362398</td>\n",
       "      <td>180700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>South Scott</td>\n",
       "      <td>OK</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Single</td>\n",
       "      <td>26508.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>26541.0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>2</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.454964</td>\n",
       "      <td>157319.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Robinhaven</td>\n",
       "      <td>PR</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>49427.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>36528.0</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>10</td>\n",
       "      <td>Fair</td>\n",
       "      <td>0.143242</td>\n",
       "      <td>287140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Heather</td>\n",
       "      <td>IL</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age      Gender Education Level Marital Status   Income  Credit Score  \\\n",
       "0   49        Male             PhD       Divorced  72799.0         688.0   \n",
       "1   57      Female      Bachelor's        Widowed      NaN         690.0   \n",
       "2   21  Non-binary        Master's         Single  55687.0         600.0   \n",
       "3   59        Male      Bachelor's         Single  26508.0         622.0   \n",
       "4   25  Non-binary      Bachelor's        Widowed  49427.0         766.0   \n",
       "\n",
       "   Loan Amount Loan Purpose Employment Status  Years at Current Job  \\\n",
       "0      45713.0     Business        Unemployed                    19   \n",
       "1      33835.0         Auto          Employed                     6   \n",
       "2      36623.0         Home          Employed                     8   \n",
       "3      26541.0     Personal        Unemployed                     2   \n",
       "4      36528.0     Personal        Unemployed                    10   \n",
       "\n",
       "  Payment History  Debt-to-Income Ratio  Assets Value  Number of Dependents  \\\n",
       "0            Poor              0.154313      120228.0                   0.0   \n",
       "1            Fair              0.148920       55849.0                   0.0   \n",
       "2            Fair              0.362398      180700.0                   3.0   \n",
       "3       Excellent              0.454964      157319.0                   3.0   \n",
       "4            Fair              0.143242      287140.0                   NaN   \n",
       "\n",
       "              City State       Country  Previous Defaults  \\\n",
       "0   Port Elizabeth    AS        Cyprus                2.0   \n",
       "1  North Catherine    OH  Turkmenistan                3.0   \n",
       "2      South Scott    OK    Luxembourg                3.0   \n",
       "3       Robinhaven    PR        Uganda                4.0   \n",
       "4      New Heather    IL       Namibia                3.0   \n",
       "\n",
       "   Marital Status Change Risk Rating  \n",
       "0                      2         Low  \n",
       "1                      2      Medium  \n",
       "2                      2      Medium  \n",
       "3                      2      Medium  \n",
       "4                      1         Low  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# file path\n",
    "file_path = \"financial_risk_assessment.csv\"\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 1: Implementing Decision Tree ðŸŒ³**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Age                    15000 non-null  int64  \n",
      " 1   Gender                 15000 non-null  object \n",
      " 2   Education Level        15000 non-null  object \n",
      " 3   Marital Status         15000 non-null  object \n",
      " 4   Income                 12750 non-null  float64\n",
      " 5   Credit Score           12750 non-null  float64\n",
      " 6   Loan Amount            12750 non-null  float64\n",
      " 7   Loan Purpose           15000 non-null  object \n",
      " 8   Employment Status      15000 non-null  object \n",
      " 9   Years at Current Job   15000 non-null  int64  \n",
      " 10  Payment History        15000 non-null  object \n",
      " 11  Debt-to-Income Ratio   15000 non-null  float64\n",
      " 12  Assets Value           12750 non-null  float64\n",
      " 13  Number of Dependents   12750 non-null  float64\n",
      " 14  City                   15000 non-null  object \n",
      " 15  State                  15000 non-null  object \n",
      " 16  Country                15000 non-null  object \n",
      " 17  Previous Defaults      12750 non-null  float64\n",
      " 18  Marital Status Change  15000 non-null  int64  \n",
      " 19  Risk Rating            15000 non-null  object \n",
      "dtypes: float64(7), int64(3), object(10)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "â— Missing Values per Column:\n",
      "Age                         0\n",
      "Gender                      0\n",
      "Education Level             0\n",
      "Marital Status              0\n",
      "Income                   2250\n",
      "Credit Score             2250\n",
      "Loan Amount              2250\n",
      "Loan Purpose                0\n",
      "Employment Status           0\n",
      "Years at Current Job        0\n",
      "Payment History             0\n",
      "Debt-to-Income Ratio        0\n",
      "Assets Value             2250\n",
      "Number of Dependents     2250\n",
      "City                        0\n",
      "State                       0\n",
      "Country                     0\n",
      "Previous Defaults        2250\n",
      "Marital Status Change       0\n",
      "Risk Rating                 0\n",
      "dtype: int64\n",
      "\n",
      "ðŸ§© Categorical Columns:\n",
      "Index(['Gender', 'Education Level', 'Marital Status', 'Loan Purpose',\n",
      "       'Employment Status', 'Payment History', 'City', 'State', 'Country',\n",
      "       'Risk Rating'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ“‹ Missing Values in Categorical Columns:\n",
      "Gender               0\n",
      "Education Level      0\n",
      "Marital Status       0\n",
      "Loan Purpose         0\n",
      "Employment Status    0\n",
      "Payment History      0\n",
      "City                 0\n",
      "State                0\n",
      "Country              0\n",
      "Risk Rating          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display general information about the dataset\n",
    "print(\"ðŸ”Ž Dataset Information:\")\n",
    "df.info()\n",
    "\n",
    "# Show number of missing values in each column\n",
    "print(\"\\nâ— Missing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=\"object\").columns\n",
    "print(\"\\nðŸ§© Categorical Columns:\")\n",
    "print(categorical_cols)\n",
    "\n",
    "# Show missing values only in categorical columnso\n",
    "print(\"\\nðŸ“‹ Missing Values in Categorical Columns:\")\n",
    "print(df[categorical_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ðŸ¤” Handling Missing Values**\n",
    "\n",
    "In this dataset, some numerical columns like *Income*, *Credit Score*, *Loan Amount*, *Assets Value*, *Number of Dependents*, and *Previous Defaults* had missing values. To fix this and make the data ready for training, we filled the missing values using the **median** of each column.\n",
    "\n",
    "We chose the median instead of the average (mean) because the median is less affected by very high or low values (outliers), which are common in financial data. This method helps us keep the data more stable and prevents our decision tree model from learning wrong patterns due to missing values.\n",
    "\n",
    "We also checked the categorical columns for missing values (such as *Gender*, *Education Level*, *Marital Status*, *Loan Purpose*, *Employment Status*, etc.), and confirmed that there were **no missing values** in these columns. Therefore, no additional imputation was needed for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                      0\n",
       "Gender                   0\n",
       "Education Level          0\n",
       "Marital Status           0\n",
       "Income                   0\n",
       "Credit Score             0\n",
       "Loan Amount              0\n",
       "Loan Purpose             0\n",
       "Employment Status        0\n",
       "Years at Current Job     0\n",
       "Payment History          0\n",
       "Debt-to-Income Ratio     0\n",
       "Assets Value             0\n",
       "Number of Dependents     0\n",
       "City                     0\n",
       "State                    0\n",
       "Country                  0\n",
       "Previous Defaults        0\n",
       "Marital Status Change    0\n",
       "Risk Rating              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of numerical columns with missing values\n",
    "numeric_missing_cols = [\n",
    "    \"Income\", \"Credit Score\", \"Loan Amount\",\n",
    "    \"Assets Value\", \"Number of Dependents\",\n",
    "    \"Previous Defaults\"\n",
    "]\n",
    "\n",
    "# Fill missing values in numeric columns using median value\n",
    "for col in numeric_missing_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Verify that all missing values have been filled\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ”  Encoding Categorical Features**\n",
    "\n",
    "To prepare the dataset for the ID3 decision tree algorithm, we manually encoded the categorical features into numerical values. This is important because the algorithm requires numerical comparisons to calculate entropy and information gain.\n",
    "\n",
    "Each category in features like *Gender*, *Education Level*, *Marital Status*, *Loan Purpose*, *Employment Status*, and *Payment History* is mapped to a unique integer. Since we are not allowed to use external encoding libraries (e.g., `sklearn.preprocessing.LabelEncoder`), all encodings are done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "gender_map = {\"Male\": 0, \"Female\": 1, \"Non-binary\": 2}\n",
    "\n",
    "# Education Level\n",
    "education_map = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "\n",
    "# Marital Status\n",
    "marital_map = {\"Single\": 0, \"Married\": 1, \"Divorced\": 2, \"Widowed\": 3}\n",
    "\n",
    "# Loan Purpose\n",
    "loan_purpose_map = {\"Home\": 0, \"Auto\": 1, \"Personal\": 2, \"Business\": 3}\n",
    "\n",
    "# Employment Status\n",
    "employment_map = {\"Unemployed\": 0, \"Employed\": 1, \"Self-employed\": 2}\n",
    "\n",
    "# Payment History\n",
    "payment_map = {\"Poor\": 0, \"Fair\": 1, \"Good\": 2, \"Excellent\": 3}\n",
    "\n",
    "# Risk Rating (Target Variable â€“ optional for printing, not encoded yet)\n",
    "risk_rating_map = {\"Low\": 0, \"Medium\": 1, \"High\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ðŸ§¹ Dropping Certain Columns Before Splitting the Data**\n",
    "Before splitting the dataset into training, validation, and test sets, we removed some columns from the feature set `X`:\n",
    "\n",
    "- **`Risk Rating`**: This is the original target column in string format. Since we already encoded it as `Risk Rating Encoded`, it is no longer needed in the input features.\n",
    "- **`Risk Rating Encoded`**: This is our label (`y`), and should not be included among the input features. Including it would lead to data leakage.\n",
    "- **`City`, `State`, and `Country`**: These columns contain too many unique values, which can make the model too complex and prone to overfitting. Additionally, they may not provide meaningful splits for a decision tree algorithm like ID3.\n",
    "\n",
    "By dropping these columns, we ensure that the input features are clean, relevant, and suitable for training the decision tree without leaking any label information or introducing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (10499, 16)\n",
      "Validation set size: (2251, 16)\n",
      "Test set size: (2250, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode the target column on-the-fly\n",
    "y = df[\"Risk Rating\"].map(risk_rating_map)\n",
    "\n",
    "# Drop non-feature columns\n",
    "X = df.drop(columns=[\"Risk Rating\", \"City\", \"State\", \"Country\"])\n",
    "\n",
    "\n",
    "# 85% train+validation, 15% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# %15 validation iÃ§in train_val'Ä± tekrar bÃ¶lelim\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val\n",
    ")\n",
    "# (0.1765 â‰ˆ 15 / 85, bÃ¶ylece %15 validation, %70 train elde edilir)\n",
    "\n",
    "# SonuÃ§larÄ± kontrol et\n",
    "print(\"Train set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate entropy of label array y\n",
    "def entropy(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-9))  # epsilon for safety\n",
    "\n",
    "# Calculate information gain of a feature in the dataset\n",
    "def information_gain(data, feature, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    values, counts = np.unique(data[feature], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    for val, count in zip(values, counts):\n",
    "        subset = data[data[feature] == val]\n",
    "        subset_entropy = entropy(subset[target])\n",
    "        weighted_entropy += (count / len(data)) * subset_entropy\n",
    "        \n",
    "    return total_entropy - weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best feature to split the data\n",
    "def best_feature_to_split(data, features, target):\n",
    "    \"\"\"Find the best feature with highest information gain\"\"\"\n",
    "    gains = [information_gain(data, feature, target) for feature in features]\n",
    "    return features[np.argmax(gains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, features, target, depth=0, max_depth=None):\n",
    "    \"\"\"Recursive ID3 algorithm\"\"\"\n",
    "    \n",
    "    # EÄŸer tÃ¼m etiketler aynÄ±ysa -> yaprak dÃ¼ÄŸÃ¼m\n",
    "    if len(np.unique(data[target])) == 1:\n",
    "        return np.unique(data[target])[0]\n",
    "    \n",
    "    # EÄŸer feature kalmadÄ±ysa -> en sÄ±k gÃ¶rÃ¼len sÄ±nÄ±f\n",
    "    if len(features) == 0:\n",
    "        return data[target].mode()[0]\n",
    "    \n",
    "    # Maksimum derinliÄŸe ulaÅŸÄ±ldÄ±ysa -> Ã§oÄŸunluk sÄ±nÄ±fÄ±\n",
    "    if max_depth is not None and depth >= max_depth:\n",
    "        return data[target].mode()[0]\n",
    "\n",
    "    # En iyi feature'Ä± bul\n",
    "    best_feature = best_feature_to_split(data, features, target)\n",
    "    \n",
    "    tree = {best_feature: {}}\n",
    "    \n",
    "    # Her unique deÄŸer iÃ§in dal oluÅŸtur\n",
    "    for value in np.unique(data[best_feature]):\n",
    "        sub_data = data[data[best_feature] == value]\n",
    "        if sub_data.empty:\n",
    "            tree[best_feature][value] = data[target].mode()[0]\n",
    "        else:\n",
    "            # Recursive call\n",
    "            remaining_features = [f for f in features if f != best_feature]\n",
    "            subtree = id3(sub_data, remaining_features, target, depth+1, max_depth)\n",
    "            tree[best_feature][value] = subtree\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(tree, sample):\n",
    "    \"\"\"Predict the class label for a single sample using the decision tree\"\"\"\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree  # reached a leaf node\n",
    "    \n",
    "    feature = next(iter(tree))\n",
    "    feature_value = sample[feature]\n",
    "    \n",
    "    if feature_value in tree[feature]:\n",
    "        return predict_single(tree[feature][feature_value], sample)\n",
    "    else:\n",
    "        # If unseen feature value during training â†’ majority class fallback\n",
    "        return -1  # or mode of training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, X):\n",
    "    \"\"\"Predict class labels for a dataset\"\"\"\n",
    "    return X.apply(lambda row: predict_single(tree, row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train.columns)\n",
    "target = \"Risk Rating Encoded\"\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "train_data = X_train.copy()\n",
    "train_data[target] = y_train\n",
    "\n",
    "# Build the decision tree\n",
    "tree = id3(train_data, features, target, max_depth=50)  # You can change max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸ Test Accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "# Tahminleri yap\n",
    "y_pred = predict(tree, X_test)\n",
    "\n",
    "# -1 varsa onlarÄ± Ã§Ä±karalÄ±m (bilinmeyen dal deÄŸerleri olabilir)\n",
    "valid_idx = y_pred != -1\n",
    "test_acc = accuracy(y_test[valid_idx], y_pred[valid_idx])\n",
    "\n",
    "print(f\"ðŸŒŸ Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
